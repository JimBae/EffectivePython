{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python programs that do many things concurrently often need to coordinate their work.\n",
    "One of the most useful arrangements for concurrent work is a pipeline of functions.\n",
    "\n",
    "A pipeline works like an assembly line used in manufacturing. Pipelines have many\n",
    "phases in serial with a specific function for each phase. New pieces of work are constantly\n",
    "added to the beginning of the pipeline. Each function can operate concurrently on the\n",
    "piece of work in its phase. The work moves forward as each function completes until there\n",
    "are no phases remaining. This approach is especially good for work that includes blocking\n",
    "I/O or subprocesses—activities that can easily be parallelized using Python (see Item 37:\n",
    "“Use Threads for Blocking I/O, Avoid for Parallelism”).\n",
    "\n",
    "For example, say you want to build a system that will take a constant stream of images\n",
    "from your digital camera, resize them, and then add them to a photo gallery online. Such a\n",
    "program could be split into three phases of a pipeline. New images are retrieved in the first\n",
    "phase. The downloaded images are passed through the resize function in the second phase.\n",
    "The resized images are consumed by the upload function in the final phase.\n",
    "\n",
    "Imagine you had already written Python functions that execute the phases: download,\n",
    "resize, upload. How do you assemble a pipeline to do the work concurrently?\n",
    "\n",
    "The first thing you need is a way to hand off work between the pipeline phases. This can\n",
    "be modeled as a thread-safe producer-consumer queue (see Item 38: “Use Lock to\n",
    "Prevent Data Races in Threads” to understand the importance of thread safety in Python;\n",
    "see Item 46: “Use Built-in Algorithms and Data Structures” for the deque class).\n",
    "\n",
    "\n",
    "### Example 5\n",
    "Here, I represent each phase of the pipeline as a Python thread that takes work from one\n",
    "queue like this, runs a function on it, and puts the result on another queue. I also track how\n",
    "many times the worker has checked for new input and how much work it’s completed.\n",
    "\n",
    "### Example 6\n",
    "The trickiest part is that the worker thread must properly handle the case where the input\n",
    "queue is empty because the previous phase hasn’t completed its work yet. This happens\n",
    "where I catch the IndexError exception below. You can think of this as a holdup in the\n",
    "assembly line.\n",
    "\n",
    "### Example 7\n",
    "Now I can connect the three phases together by creating the queues for their coordination\n",
    "points and the corresponding worker threads.\n",
    "\n",
    "### Example 8\n",
    "I can start the threads and then inject a bunch of work into the first phase of the pipeline.\n",
    "Here, I use a plain object instance as a proxy for the real data required by the\n",
    "download function:\n",
    "\n",
    "### Example 9\n",
    "Now I wait for all of the items to be processed by the pipeline and end up in the done_queue.\n",
    "\n",
    "### Example 10\n",
    "This runs properly, but there’s an interesting side effect caused by the threads polling their\n",
    "input queues for new work. The tricky part, where I catch IndexError exceptions in the\n",
    "run method, executes a large number of times.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from pprint import pprint\n",
    "from sys import stdout as STDOUT\n",
    "\n",
    "\n",
    "# Example 1\n",
    "def download(item):\n",
    "    return item\n",
    "\n",
    "def resize(item):\n",
    "    return item\n",
    "\n",
    "def upload(item):\n",
    "    return item\n",
    "\n",
    "\n",
    "# Example 2\n",
    "from threading import Lock\n",
    "from collections import deque\n",
    "\n",
    "class MyQueue(object):\n",
    "    def __init__(self):\n",
    "        self.items = deque()\n",
    "        self.lock = Lock()\n",
    "\n",
    "\n",
    "# Example 3\n",
    "    def put(self, item):\n",
    "        with self.lock:\n",
    "            self.items.append(item)\n",
    "\n",
    "\n",
    "# Example 4\n",
    "    def get(self):\n",
    "        with self.lock:\n",
    "            return self.items.popleft()\n",
    "\n",
    "\n",
    "# Example 5\n",
    "from threading import Thread\n",
    "from time import sleep\n",
    "\n",
    "class Worker(Thread):\n",
    "    def __init__(self, func, in_queue, out_queue):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        self.in_queue = in_queue\n",
    "        self.out_queue = out_queue\n",
    "        self.polled_count = 0\n",
    "        self.work_done = 0\n",
    "\n",
    "\n",
    "# Example 6\n",
    "    def run(self):\n",
    "        while True:\n",
    "            self.polled_count += 1\n",
    "            try:\n",
    "                item = self.in_queue.get()\n",
    "            except IndexError:\n",
    "                sleep(0.01)  # No work to do\n",
    "            except AttributeError:\n",
    "                # The magic exit signal\n",
    "                return\n",
    "            else:\n",
    "                result = self.func(item)\n",
    "                self.out_queue.put(result)\n",
    "                self.work_done += 1\n",
    "\n",
    "\n",
    "# Example 7\n",
    "download_queue = MyQueue()\n",
    "resize_queue = MyQueue()\n",
    "upload_queue = MyQueue()\n",
    "done_queue = MyQueue()\n",
    "threads = [\n",
    "    Worker(download, download_queue, resize_queue),\n",
    "    Worker(resize, resize_queue, upload_queue),\n",
    "    Worker(upload, upload_queue, done_queue),\n",
    "]\n",
    "\n",
    "\n",
    "# Example 8\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "for _ in range(1000):\n",
    "    download_queue.put(object())\n",
    "\n",
    "    \n",
    "# Example 9\n",
    "import time\n",
    "while len(done_queue.items) < 1000:\n",
    "    # Do something useful while waiting\n",
    "    time.sleep(0.1)\n",
    "# Stop all the threads by causing an exception in their\n",
    "# run methods.\n",
    "for thread in threads:\n",
    "    thread.in_queue = None\n",
    "\n",
    "\n",
    "# Example 10\n",
    "processed = len(done_queue.items)\n",
    "polled = sum(t.polled_count for t in threads)\n",
    "print('Processed', processed, 'items after polling',\n",
    "      polled, 'times')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the worker functions vary in speeds, an earlier phase can prevent progress in later\n",
    "phases, backing up the pipeline. This causes later phases to starve and constantly check\n",
    "their input queues for new work in a tight loop. The outcome is that worker threads waste\n",
    "CPU time doing nothing useful (they’re constantly raising and catching IndexError\n",
    "exceptions).\n",
    "\n",
    "But that’s just the beginning of what’s wrong with this implementation. There are three\n",
    "more problems that you should also avoid. First, determining that all of the input work is\n",
    "complete requires yet another busy wait on the done_queue. Second, in Worker the\n",
    "run method will execute forever in its busy loop. There’s no way to signal to a worker\n",
    "thread that it’s time to exit.\n",
    "\n",
    "Third, and worst of all, a backup in the pipeline can cause the program to crash arbitrarily.\n",
    "If the first phase makes rapid progress but the second phase makes slow progress, then the\n",
    "queue connecting the first phase to the second phase will constantly increase in size. The\n",
    "second phase won’t be able to keep up. Given enough time and input data, the program\n",
    "will eventually run out of memory and die.\n",
    "The lesson here isn’t that pipelines are bad; it’s that it’s hard to build a good producerconsumer\n",
    "\n",
    "queue yourself.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> Queue to the Rescue\n",
    "\n",
    "The Queue class from the queue built-in module provides all of the functionality you\n",
    "need to solve these problems.\n",
    "\n",
    "### Ex 11\n",
    "Queue eliminates the busy waiting in the worker by making the get method block until\n",
    "new data is available. For example, here I start a thread that waits for some input data on a\n",
    "queue:\n",
    "\n",
    "### Ex 12\n",
    "Even though the thread is running first, it won’t finish until an item is put on the Queue\n",
    "instance and the get method has something to return.\n",
    "\n",
    "### Ex 13\n",
    "To solve the pipeline backup issue, the Queue class lets you specify the maximum\n",
    "amount of pending work you’ll allow between two phases. This buffer size causes calls to\n",
    "put to block when the queue is already full. For example, here I define a thread that waits\n",
    "for a while before consuming a queue:\n",
    "\n",
    "### Ex 14\n",
    "The wait should allow the producer thread to put both objects on the queue before the\n",
    "consume thread ever calls get. But the Queue size is one. That means the producer\n",
    "adding items to the queue will have to wait for the consumer thread to call get at least\n",
    "once before the second call to put will stop blocking and add the second item to the\n",
    "queue.\n",
    "\n",
    "\n",
    "### Ex 15\n",
    "The Queue class can also track the progress of work using the task_done method. This\n",
    "lets you wait for a phase’s input queue to drain and eliminates the need for polling the\n",
    "done_queue at the end of your pipeline. For example, here I define a consumer thread\n",
    "that calls task_done when it finishes working on an item.\n",
    "\n",
    "### Ex 16\n",
    "Now, the producer code doesn’t have to join the consumer thread or poll. The producer\n",
    "can just wait for the in_queue to finish by calling join on the Queue instance. Even\n",
    "once it’s empty, the in_queue won’t be joinable until after task_done is called for\n",
    "every item that was ever enqueued.\n",
    "\n",
    "### Ex 17\n",
    "I can put all of these behaviors together into a Queue subclass that also tells the worker\n",
    "thread when it should stop processing. Here, I define a close method that adds a special\n",
    "item to the queue that indicates there will be no more input items after it:\n",
    "\n",
    "### Ex 18\n",
    "Then, I define an iterator for the queue that looks for this special object and stops iteration when it’s found. This __iter__ method also calls task_done at appropriate times,\n",
    "letting me track the progress of work on the queue.\n",
    "\n",
    "### Ex 19\n",
    "Now, I can redefine my worker thread to rely on the behavior of the ClosableQueue\n",
    "class. The thread will exit once the for loop is exhausted.\n",
    "\n",
    "### Ex 20\n",
    "Here, I re-create the set of worker threads using the new worker class:\n",
    "\n",
    "### Ex 21\n",
    "After running the worker threads like before, I also send the stop signal once all the input\n",
    "work has been injected by closing the input queue of the first phase.\n",
    "\n",
    "### Ex 22\n",
    "Finally, I wait for the work to finish by joining each queue that connects the phases. Each\n",
    "time one phase is done, I signal the next phase to stop by closing its input queue. At the\n",
    "end, the done_queue contains all of the output objects as expected.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Consumer waiting1000\n",
      " Consumer doneitems after polling\n",
      " 3028 times\n",
      "Producer putting\n",
      "Producer done\n",
      "Producer put 1\n",
      "Consumer got 1\n",
      "Producer put 2Consumer got 2\n",
      "Consumer waiting\n",
      "Producer done\n",
      "Consumer working\n",
      "\n",
      "Producer waitingConsumer done\n",
      "\n",
      "Producer done\n",
      "1000 items finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example 11\n",
    "from queue import Queue\n",
    "queue = Queue()\n",
    "\n",
    "def consumer():\n",
    "    print('Consumer waiting')\n",
    "    queue.get()                # Runs after put() below\n",
    "    print('Consumer done')\n",
    "\n",
    "thread = Thread(target=consumer)\n",
    "thread.start()\n",
    "\n",
    "\n",
    "# Example 12\n",
    "print('Producer putting')\n",
    "queue.put(object())            # Runs before get() above\n",
    "thread.join()\n",
    "print('Producer done')\n",
    "\n",
    "\n",
    "# Example 13\n",
    "queue = Queue(1)               # Buffer size of 1\n",
    "\n",
    "def consumer():\n",
    "    time.sleep(0.1)            # Wait\n",
    "    queue.get()                # Runs second\n",
    "    print('Consumer got 1')\n",
    "    queue.get()                # Runs fourth\n",
    "    print('Consumer got 2')\n",
    "\n",
    "thread = Thread(target=consumer)\n",
    "thread.start()\n",
    "\n",
    "\n",
    "# Example 14\n",
    "queue.put(object())            # Runs first\n",
    "print('Producer put 1')\n",
    "queue.put(object())            # Runs third\n",
    "print('Producer put 2')\n",
    "thread.join()\n",
    "print('Producer done')\n",
    "\n",
    "\n",
    "# Example 15\n",
    "in_queue = Queue()\n",
    "\n",
    "def consumer():\n",
    "    print('Consumer waiting')\n",
    "    work = in_queue.get()      # Done second\n",
    "    print('Consumer working')\n",
    "    # Doing work\n",
    "    print('Consumer done')\n",
    "    in_queue.task_done()       # Done third\n",
    "\n",
    "Thread(target=consumer).start()\n",
    "\n",
    "\n",
    "# Example 16\n",
    "in_queue.put(object())         # Done first\n",
    "print('Producer waiting')\n",
    "in_queue.join()                # Done fourth\n",
    "print('Producer done')\n",
    "\n",
    "\n",
    "# Example 17\n",
    "class ClosableQueue(Queue):\n",
    "    SENTINEL = object()\n",
    "\n",
    "    def close(self):\n",
    "        self.put(self.SENTINEL)\n",
    "\n",
    "\n",
    "# Example 18\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            item = self.get()\n",
    "            try:\n",
    "                if item is self.SENTINEL:\n",
    "                    return  # Cause the thread to exit\n",
    "                yield item\n",
    "            finally:\n",
    "                self.task_done()\n",
    "\n",
    "\n",
    "# Example 19\n",
    "class StoppableWorker(Thread):\n",
    "    def __init__(self, func, in_queue, out_queue):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        self.in_queue = in_queue\n",
    "        self.out_queue = out_queue\n",
    "\n",
    "    def run(self):\n",
    "        for item in self.in_queue:\n",
    "            result = self.func(item)\n",
    "            self.out_queue.put(result)\n",
    "\n",
    "\n",
    "# Example 20\n",
    "download_queue = ClosableQueue()\n",
    "resize_queue = ClosableQueue()\n",
    "upload_queue = ClosableQueue()\n",
    "done_queue = ClosableQueue()\n",
    "threads = [\n",
    "    StoppableWorker(download, download_queue, resize_queue),\n",
    "    StoppableWorker(resize, resize_queue, upload_queue),\n",
    "    StoppableWorker(upload, upload_queue, done_queue),\n",
    "]\n",
    "\n",
    "\n",
    "# Example 21\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "for _ in range(1000):\n",
    "    download_queue.put(object())\n",
    "download_queue.close()\n",
    "\n",
    "\n",
    "# Example 22\n",
    "download_queue.join()\n",
    "resize_queue.close()\n",
    "resize_queue.join()\n",
    "upload_queue.close()\n",
    "upload_queue.join()\n",
    "print(done_queue.qsize(), 'items finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pipelines are a great way to organize sequences of work that run concurrently using multiple Python threads.\n",
    "* Be aware of the many problems in building concurrent pipelines: busy waiting, stopping workers, and memory explosion.\n",
    "* The Queue class has all of the facilities you need to build robust pipelines: blocking operations, buffer sizes, and joining."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
