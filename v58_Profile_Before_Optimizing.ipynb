{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dynamic nature of Python causes surprising behaviors in its runtime performance.\n",
    "Operations you might assume are slow are actually very fast (string manipulation,\n",
    "generators). Language features you might assume are fast are actually very slow (attribute\n",
    "access, function calls). The true source of slowdowns in a Python program can be obscure.\n",
    "\n",
    "The best approach is to ignore your intuition and directly measure the performance of a\n",
    "program before you try to optimize it. Python provides a built-in profiler for determining\n",
    "which parts of a program are responsible for its execution time. This lets you focus your\n",
    "optimization efforts on the biggest sources of trouble and ignore parts of the program that\n",
    "don’t impact speed.\n",
    "\n",
    "For example, say you want to determine why an algorithm in your program is slow. Here,\n",
    "I define a function that sorts a list of data using an insertion sort:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core mechanism of the insertion sort is the function that finds the insertion point for\n",
    "each piece of data. Here, I define an extremely inefficient version of the insert_value\n",
    "function that does a linear scan over the input array:\n",
    "    \n",
    "To profile insertion_sort and insert_value, I create a data set of random\n",
    "numbers and define a test function to pass to the profiler.\n",
    "\n",
    "Python provides two built-in profilers, one that is pure Python (profile) and another\n",
    "that is a C-extension module (cProfile). The cProfile built-in module is better\n",
    "because of its minimal impact on the performance of your program while it’s being\n",
    "profiled. The pure-Python alternative imposes a high overhead that will skew the results.\n",
    "\n",
    "\n",
    "### Note\n",
    "When profiling a Python program, be sure that what you’re measuring is the code\n",
    "itself and not any external systems. Beware of functions that access the network or\n",
    "resources on disk. These may appear to have a large impact on your program’s\n",
    "execution time because of the slowness of the underlying systems. If your program\n",
    "uses a cache to mask the latency of slow resources like these, you should also\n",
    "ensure that it’s properly warmed up before you start profiling.\n",
    "\n",
    "Here, I instantiate a Profile object from the cProfile module and run the test\n",
    "function through it using the runcall method:\n",
    "\n",
    "    profiler = Profile()\n",
    "    profiler.runcall(test)\n",
    "    \n",
    "Once the test function has finished running, I can extract statistics about its performance\n",
    "using the pstats built-in module and its Stats class. Various methods on a Stats\n",
    "object adjust how to select and sort the profiling information to show only the things you\n",
    "care about.\n",
    "\n",
    "    stats = Stats(profiler)\n",
    "    stats.strip_dirs()\n",
    "    stats.sort_stats(‘cumulative’)\n",
    "    stats.print_stats()\n",
    "    \n",
    "The output is a table of information organized by function. The data sample is taken only\n",
    "from the time the profiler was active, during the runcall method above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s a quick guide to what the profiler statistics columns mean:\n",
    " - ncalls: The number of calls to the function during the profiling period.\n",
    " - tottime: The number of seconds spent executing the function, excluding time spent executing other functions it calls.\n",
    " - tottime percall: The average number of seconds spent in the function each time it was called, excluding time spent executing other functions it calls. This is tottime divided by ncalls.\n",
    " - cumtime: The cumulative number of seconds spent executing the function, including time spent in all other functions it calls.\n",
    " - cumtime percall: The average number of seconds spent in the function each time it was called, including time spent in all other functions it calls. This is cumtime divided by ncalls.\n",
    " \n",
    "Looking at the profiler statistics table above, I can see that the biggest use of CPU in my\n",
    "test is the cumulative time spent in the insert_value function. Here, I redefine that\n",
    "function to use the bisect built-in module (see Item 46: “Use Built-in Algorithms and\n",
    "Data Structures”):\n",
    "\n",
    "I can run the profiler again and generate a new table of profiler statistics. The new\n",
    "function is much faster, with a cumulative time spent that is nearly 100× smaller than the\n",
    "previous insert_value function.\n",
    "\n",
    "Sometimes, when you’re profiling an entire program, you’ll find that a common utility\n",
    "function is responsible for the majority of execution time. The default output from the\n",
    "profiler makes this situation difficult to understand because it doesn’t show how the utility\n",
    "function is called by many different parts of your program.\n",
    "For example, here the my_utility function is called repeatedly by two different\n",
    "functions in the program:\n",
    "\n",
    "Profiling this code and using the default print_stats output will generate output\n",
    "statistics that are confusing.\n",
    "\n",
    "The my_utility function is clearly the source of most execution time, but it’s not\n",
    "immediately obvious why that function is called so much. If you search through the\n",
    "program’s code, you’ll find multiple call sites for my_utility and still be confused.\n",
    "To deal with this, the Python profiler provides a way of seeing which callers contributed to\n",
    "the profiling information of each function.\n",
    "\n",
    "stats.print_callers()\n",
    "\n",
    "This profiler statistics table shows functions called on the left and who was responsible for\n",
    "making the call on the right. Here, it’s clear that my_utility is most used by\n",
    "first_func:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It’s important to profile Python programs before optimizing because the source of slowdowns is often obscure.\n",
    "\n",
    "* Use the cProfile module instead of the profile module because it provides more accurate profiling information.\n",
    "\n",
    "* The Profile object’s runcall method provides everything you need to profile a tree of function calls in isolation.\n",
    "\n",
    "* The Stats object lets you select and print the subset of profiling information you need to see to understand your program’s performance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
